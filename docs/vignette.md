# Vignette: The "Type-Safe" Extraction

This vignette demonstrates how to use `coreason-construct` to build a robust, type-safe application for extracting Adverse Events from clinical notes.

## Scenario

Dr. Smith has provided a set of clinical notes in unstructured text format. We need to extract all Adverse Events (AEs) mentioned in these notes, ensuring that each extracted AE adheres to a strict schema (e.g., standard terminology, severity grading).

## The Goal

Transform raw text:
> "Patient 001 reported feeling nausea about 30 minutes after the infusion. Severity was mild, resolved without medication."

Into a structured object:
```json
{
  "term": "nausea",
  "severity": "MILD",
  "onset": "30 minutes after infusion",
  "outcome": "RESOLVED"
}
```

## Step 1: Define the Schema

First, we define the target structure using Pydantic. This is the contract the LLM must fulfill.

```python
from pydantic import BaseModel, Field
from enum import Enum
from typing import Optional

class Severity(str, Enum):
    MILD = "MILD"
    MODERATE = "MODERATE"
    SEVERE = "SEVERE"

class AdverseEvent(BaseModel):
    term: str = Field(..., description="The medical term for the adverse event.")
    severity: Severity = Field(..., description="The severity of the event.")
    onset: Optional[str] = Field(None, description="When the event started relative to the intervention.")
    outcome: Optional[str] = Field(None, description="The outcome of the event.")
```

## Step 2: Assemble the Prompt with Weaver

We use the `Weaver` to assemble the cognitive components necessary for this task.

```python
from coreason_construct import Weaver
from coreason_construct.roles.library import SafetyScientist
from coreason_construct.data.library import AE_Examples
from coreason_construct.primitives.extract import ExtractionPrimitive

# Initialize Weaver
weaver = Weaver()

# 1. Identity: Safety Scientist
# This role comes with inherent biases towards safety reporting and precise terminology.
# It also automatically injects the 'GxP_Guidelines' context.
weaver.add(SafetyScientist)

# 2. Data: Few-Shot Examples
# We inject a bank of "gold standard" examples to guide the model on edge cases.
# E.g., Distinguishing between a symptom and a medical history item.
weaver.add(AE_Examples)

# 3. Task: Extraction Primitive
# We define the specific task: Extract data into the 'AdverseEvent' schema.
extractor = ExtractionPrimitive(
    name="AE_Extraction_Task",
    schema=AdverseEvent
)
weaver.add(extractor)
```

## Step 3: Execution

Now we process the clinical note.

```python
import instructor
import openai

# The input text
clinical_note = "Patient 001 reported feeling nausea about 30 minutes after the infusion. Severity was mild, resolved without medication."

# Build the prompt configuration
config = weaver.build(clinical_note)

# Setup the client (patched with instructor)
client = instructor.patch(openai.OpenAI())

# Call the LLM
result = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": config.system_message},
        {"role": "user", "content": config.user_message}
    ],
    response_model=config.response_model
)

# Result is a validated 'AdverseEvent' object
print(f"Event: {result.term}")       # Event: nausea
print(f"Severity: {result.severity}") # Severity: MILD
```

## Why this is better than a raw prompt

1.  **Type Safety:** The output is guaranteed to be a valid `AdverseEvent` object, or the library raises a validation error.
2.  **Contextual Integrity:** The `SafetyScientist` role ensures the extraction respects medical nuances.
3.  **Auditability:** The `config.provenance_metadata` (generated by `weaver.build`) allows us to log exactly which Role, Contexts, and Schema were used for this specific extraction, fulfilling compliance requirements.
